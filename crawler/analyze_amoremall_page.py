#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì•„ëª¨ë ˆëª° í˜ì´ì§€ êµ¬ì¡° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
"""

import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

def analyze_page():
    """ì•„ëª¨ë ˆëª° í˜ì´ì§€ êµ¬ì¡° ë¶„ì„"""
    
    # ChromeDriver ì„¤ì •
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--window-size=1920,1080')
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    
    try:
        url = "https://www.amoremall.com/kr/ko/display/live/playerweb?sy_id=678f729865cf422cde50d959&sy_type=broadcast"
        print(f"í˜ì´ì§€ ë¡œë”©: {url}")
        
        driver.get(url)
        time.sleep(10)  # ì¶©ë¶„í•œ ë¡œë”© ì‹œê°„
        
        # í˜ì´ì§€ ì†ŒìŠ¤ ì €ì¥
        with open('amoremall_page_source.html', 'w', encoding='utf-8') as f:
            f.write(driver.page_source)
        print("âœ… í˜ì´ì§€ ì†ŒìŠ¤ ì €ì¥: amoremall_page_source.html")
        
        # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
        driver.save_screenshot('amoremall_screenshot.png')
        print("âœ… ìŠ¤í¬ë¦°ìƒ· ì €ì¥: amoremall_screenshot.png")
        
        # BeautifulSoupìœ¼ë¡œ íŒŒì‹±
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        print("\n" + "=" * 80)
        print("ğŸ“‹ í˜ì´ì§€ êµ¬ì¡° ë¶„ì„")
        print("=" * 80)
        
        # 1. ì œëª© ì°¾ê¸°
        print("\n1. ì œëª© í›„ë³´:")
        for tag in ['h1', 'h2', 'h3']:
            elements = soup.find_all(tag)
            for elem in elements[:3]:
                text = elem.get_text(strip=True)
                if text:
                    print(f"   - {tag}: {text[:100]}")
        
        # 2. í´ë˜ìŠ¤ëª… ë¶„ì„
        print("\n2. ì£¼ìš” í´ë˜ìŠ¤ëª…:")
        all_classes = set()
        for elem in soup.find_all(class_=True):
            for cls in elem.get('class', []):
                if any(keyword in cls.lower() for keyword in ['product', 'goods', 'item', 'coupon', 'benefit', 'comment', 'reply', 'faq']):
                    all_classes.add(cls)
        
        for cls in sorted(all_classes)[:20]:
            print(f"   - {cls}")
        
        # 3. ìƒí’ˆ ê´€ë ¨ ìš”ì†Œ
        print("\n3. ìƒí’ˆ ê´€ë ¨ ìš”ì†Œ:")
        product_keywords = ['product', 'goods', 'item']
        for keyword in product_keywords:
            elements = soup.find_all(class_=lambda x: x and keyword in x.lower())
            if elements:
                print(f"   - .{keyword}*: {len(elements)}ê°œ ë°œê²¬")
                if elements:
                    print(f"     ì˜ˆì‹œ í´ë˜ìŠ¤: {elements[0].get('class')}")
        
        # 4. í˜œíƒ/ì¿ í° ê´€ë ¨ ìš”ì†Œ
        print("\n4. í˜œíƒ/ì¿ í° ê´€ë ¨ ìš”ì†Œ:")
        benefit_keywords = ['coupon', 'benefit', 'promotion']
        for keyword in benefit_keywords:
            elements = soup.find_all(class_=lambda x: x and keyword in x.lower())
            if elements:
                print(f"   - .{keyword}*: {len(elements)}ê°œ ë°œê²¬")
        
        # 5. FAQ ê´€ë ¨ ìš”ì†Œ
        print("\n5. FAQ ê´€ë ¨ ìš”ì†Œ:")
        faq_keywords = ['faq', 'qa', 'question']
        for keyword in faq_keywords:
            elements = soup.find_all(class_=lambda x: x and keyword in x.lower())
            if elements:
                print(f"   - .{keyword}*: {len(elements)}ê°œ ë°œê²¬")
        
        # 6. ëŒ“ê¸€ ê´€ë ¨ ìš”ì†Œ
        print("\n6. ëŒ“ê¸€ ê´€ë ¨ ìš”ì†Œ:")
        comment_keywords = ['comment', 'reply', 'review']
        for keyword in comment_keywords:
            elements = soup.find_all(class_=lambda x: x and keyword in x.lower())
            if elements:
                print(f"   - .{keyword}*: {len(elements)}ê°œ ë°œê²¬")
        
        # 7. ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìƒ˜í”Œ)
        print("\n7. í˜ì´ì§€ ì£¼ìš” í…ìŠ¤íŠ¸ (ì²˜ìŒ 20ì¤„):")
        all_text = soup.get_text(separator='\n', strip=True)
        lines = [line for line in all_text.split('\n') if line.strip()]
        for line in lines[:20]:
            if len(line) > 5:  # ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸
                print(f"   {line[:100]}")
        
        # 8. iframe í™•ì¸
        print("\n8. iframe í™•ì¸:")
        iframes = driver.find_elements(By.TAG_NAME, 'iframe')
        print(f"   - iframe ê°œìˆ˜: {len(iframes)}ê°œ")
        for idx, iframe in enumerate(iframes, 1):
            src = iframe.get_attribute('src')
            print(f"   - iframe {idx}: {src}")
        
        print("\n" + "=" * 80)
        print("âœ… ë¶„ì„ ì™„ë£Œ")
        print("=" * 80)
        
    finally:
        driver.quit()


if __name__ == "__main__":
    analyze_page()

