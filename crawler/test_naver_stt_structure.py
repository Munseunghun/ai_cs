#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë„¤ì´ë²„ ì‡¼í•‘ë¼ì´ë¸Œ í˜ì´ì§€ êµ¬ì¡° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ í˜ì´ì§€ì—ì„œ STT ê´€ë ¨ ì •ë³´ê°€ ì–´ë””ì— ìˆëŠ”ì§€ í™•ì¸
"""

import time
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import json

def analyze_naver_live_page(p_url):
    """ë„¤ì´ë²„ ì‡¼í•‘ë¼ì´ë¸Œ í˜ì´ì§€ êµ¬ì¡° ë¶„ì„"""
    
    # Chrome ì˜µì…˜ ì„¤ì •
    options = Options()
    # headless ëª¨ë“œ ë¹„í™œì„±í™” (ë””ë²„ê¹…ìš©)
    # options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36')
    
    # ë“œë¼ì´ë²„ ì´ˆê¸°í™”
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    
    try:
        print(f"ğŸ” í˜ì´ì§€ ë¡œë“œ ì¤‘: {p_url}")
        driver.get(p_url)
        time.sleep(5)
        
        # ìŠ¤í¬ë¡¤í•˜ì—¬ ëª¨ë“  ì½˜í…ì¸  ë¡œë“œ
        print("ğŸ“œ ìŠ¤í¬ë¡¤í•˜ì—¬ ì½˜í…ì¸  ë¡œë“œ ì¤‘...")
        for i in range(5):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
        
        # HTML íŒŒì‹±
        html = driver.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        print("\n" + "=" * 80)
        print("ğŸ“Š í˜ì´ì§€ êµ¬ì¡° ë¶„ì„ ê²°ê³¼")
        print("=" * 80)
        
        # 1. ëª¨ë“  í´ë˜ìŠ¤ëª… ìˆ˜ì§‘
        print("\n1ï¸âƒ£ ì£¼ìš” í´ë˜ìŠ¤ëª…:")
        all_classes = set()
        for element in soup.find_all(class_=True):
            classes = element.get('class', [])
            all_classes.update(classes)
        
        # STT ê´€ë ¨ í‚¤ì›Œë“œë¡œ í•„í„°ë§
        stt_keywords = ['timeline', 'chapter', 'comment', 'chat', 'message', 'qa', 'question', 
                        'answer', 'highlight', 'key', 'important', 'product', 'item', 'host', 
                        'presenter', 'reaction', 'like', 'heart', 'time', 'stamp']
        
        relevant_classes = [cls for cls in all_classes if any(keyword in cls.lower() for keyword in stt_keywords)]
        for cls in sorted(relevant_classes)[:30]:
            print(f"   - {cls}")
        
        # 2. ë°ì´í„° ì†ì„± í™•ì¸
        print("\n2ï¸âƒ£ ë°ì´í„° ì†ì„± (data-*):")
        data_attrs = set()
        for element in soup.find_all():
            for attr in element.attrs:
                if attr.startswith('data-'):
                    data_attrs.add(attr)
        
        for attr in sorted(data_attrs)[:20]:
            print(f"   - {attr}")
        
        # 3. ë¹„ë””ì˜¤ ê´€ë ¨ ìš”ì†Œ
        print("\n3ï¸âƒ£ ë¹„ë””ì˜¤ ê´€ë ¨ ìš”ì†Œ:")
        video_elements = soup.find_all(['video', 'iframe'])
        print(f"   - ë¹„ë””ì˜¤ ìš”ì†Œ: {len(video_elements)}ê°œ")
        for video in video_elements[:3]:
            print(f"     * {video.name}: {video.get('src', 'N/A')[:80]}")
        
        # 4. ìŠ¤í¬ë¦½íŠ¸ íƒœê·¸ì—ì„œ JSON ë°ì´í„° ì°¾ê¸°
        print("\n4ï¸âƒ£ ìŠ¤í¬ë¦½íŠ¸ ë‚´ JSON ë°ì´í„°:")
        scripts = soup.find_all('script')
        for script in scripts:
            script_text = script.string
            if script_text and ('timeline' in script_text.lower() or 'product' in script_text.lower() or 'chat' in script_text.lower()):
                # JSON íŒ¨í„´ ì°¾ê¸°
                import re
                json_patterns = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', script_text)
                if json_patterns:
                    print(f"   - JSON ë°ì´í„° ë°œê²¬: {len(json_patterns)}ê°œ")
                    for pattern in json_patterns[:2]:
                        if len(pattern) < 200:
                            print(f"     * {pattern[:100]}...")
        
        # 5. í…ìŠ¤íŠ¸ ì½˜í…ì¸  ìƒ˜í”Œ
        print("\n5ï¸âƒ£ í…ìŠ¤íŠ¸ ì½˜í…ì¸  ìƒ˜í”Œ:")
        
        # ì œëª©
        title_candidates = soup.select('h1, h2, [class*="title"]')
        if title_candidates:
            print(f"   ì œëª©: {title_candidates[0].get_text(strip=True)[:100]}")
        
        # ì„¤ëª…
        desc_candidates = soup.select('[class*="description"], [class*="desc"]')
        if desc_candidates:
            print(f"   ì„¤ëª…: {desc_candidates[0].get_text(strip=True)[:100]}")
        
        # 6. ë©”íƒ€ ì •ë³´
        print("\n6ï¸âƒ£ ë©”íƒ€ ì •ë³´:")
        meta_tags = soup.find_all('meta')
        for meta in meta_tags:
            property_name = meta.get('property') or meta.get('name')
            content = meta.get('content')
            if property_name and content and any(keyword in property_name.lower() for keyword in ['title', 'description', 'image']):
                print(f"   - {property_name}: {content[:80]}")
        
        # 7. êµ¬ì¡°í™”ëœ ë°ì´í„° (JSON-LD)
        print("\n7ï¸âƒ£ êµ¬ì¡°í™”ëœ ë°ì´í„° (JSON-LD):")
        json_ld_scripts = soup.find_all('script', type='application/ld+json')
        for script in json_ld_scripts:
            try:
                data = json.loads(script.string)
                print(f"   - íƒ€ì…: {data.get('@type', 'Unknown')}")
                if 'name' in data:
                    print(f"     ì´ë¦„: {data['name'][:80]}")
                if 'description' in data:
                    print(f"     ì„¤ëª…: {data['description'][:80]}")
            except:
                pass
        
        # 8. í˜ì´ì§€ ì „ì²´ HTML ì €ì¥ (ë””ë²„ê¹…ìš©)
        output_file = '/Users/amore/ai_cs ì‹œìŠ¤í…œ/crawler/logs/naver_live_page_structure.html'
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html)
        print(f"\nğŸ’¾ ì „ì²´ HTML ì €ì¥: {output_file}")
        
        print("\n" + "=" * 80)
        
    finally:
        driver.quit()
        print("âœ… ë¸Œë¼ìš°ì € ì¢…ë£Œ")


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸í•  URL (ì‹¤ì œ ë„¤ì´ë²„ ì‡¼í•‘ë¼ì´ë¸Œ URLë¡œ ë³€ê²½)
    test_url = "https://view.shoppinglive.naver.com/replays/1775352"
    
    print("ğŸ¬ ë„¤ì´ë²„ ì‡¼í•‘ë¼ì´ë¸Œ í˜ì´ì§€ êµ¬ì¡° ë¶„ì„ ì‹œì‘")
    print("=" * 80)
    
    analyze_naver_live_page(test_url)
    
    print("\nâœ… ë¶„ì„ ì™„ë£Œ!")
