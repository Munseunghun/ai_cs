#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì‹¤ì œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ë„¤ì´ë²„ ì‡¼í•‘ë¼ì´ë¸Œì—ì„œ ì‹¤ì œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìˆëŠ”ì§€ í…ŒìŠ¤íŠ¸
"""

import sys
import time
import logging
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_naver_crawling():
    """ë„¤ì´ë²„ ì‡¼í•‘ë¼ì´ë¸Œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸"""
    
    logger.info("=" * 80)
    logger.info("ğŸ§ª ë„¤ì´ë²„ ì‡¼í•‘ë¼ì´ë¸Œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 80)
    
    driver = None
    
    try:
        # Chrome ì˜µì…˜ ì„¤ì •
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        options.add_argument('user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        # ChromeDriver ìë™ ì„¤ì¹˜ ë° ì´ˆê¸°í™”
        logger.info("ChromeDriver ì´ˆê¸°í™” ì¤‘...")
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        logger.info("âœ… ChromeDriver ì´ˆê¸°í™” ì™„ë£Œ")
        
        # í…ŒìŠ¤íŠ¸ 1: ë„¤ì´ë²„ ì‡¼í•‘ë¼ì´ë¸Œ ë©”ì¸ í˜ì´ì§€
        logger.info("\ní…ŒìŠ¤íŠ¸ 1: ë©”ì¸ í˜ì´ì§€ ì ‘ì†")
        driver.get("https://shoppinglive.naver.com")
        time.sleep(3)
        
        logger.info(f"   í˜ì´ì§€ ì œëª©: {driver.title}")
        logger.info(f"   í˜„ì¬ URL: {driver.current_url}")
        
        # í…ŒìŠ¤íŠ¸ 2: ë¼ë„¤ì¦ˆ ë¸Œëœë“œ ê²€ìƒ‰
        test_brand = "ë¼ë„¤ì¦ˆ"
        logger.info(f"\ní…ŒìŠ¤íŠ¸ 2: '{test_brand}' ë¸Œëœë“œ ê²€ìƒ‰")
        
        import urllib.parse
        encoded_brand = urllib.parse.quote(test_brand)
        search_url = f"https://shoppinglive.naver.com/search/lives?query={encoded_brand}"
        
        logger.info(f"   ê²€ìƒ‰ URL: {search_url}")
        driver.get(search_url)
        time.sleep(3)
        
        # ìŠ¤í¬ë¡¤í•˜ì—¬ ë” ë§ì€ ê²°ê³¼ ë¡œë“œ
        logger.info("   í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì¤‘...")
        for i in range(3):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1.5)
        
        # HTML íŒŒì‹±
        html = driver.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        # ë¼ì´ë¸Œ ë°©ì†¡ ë§í¬ ì°¾ê¸°
        logger.info("   ë¼ì´ë¸Œ ë°©ì†¡ ë§í¬ ê²€ìƒ‰ ì¤‘...")
        
        # ì—¬ëŸ¬ ì„ íƒì ì‹œë„
        selectors = [
            'a[href*="/replays/"]',
            'a[href*="/lives/"]',
            'a[href*="view.shoppinglive.naver.com"]',
            '.live-item a',
            '[class*="live"] a[href]',
            'a.link',
        ]
        
        found_links = []
        for selector in selectors:
            links = soup.select(selector)
            logger.info(f"   ì„ íƒì '{selector}': {len(links)}ê°œ ë§í¬ ë°œê²¬")
            
            for link in links[:5]:  # ì²˜ìŒ 5ê°œë§Œ í™•ì¸
                href = link.get('href')
                if href:
                    logger.info(f"      - {href[:100]}")
                    if '/replays/' in href or '/lives/' in href:
                        if href not in found_links:
                            found_links.append(href)
        
        logger.info(f"\n   âœ… ì´ {len(found_links)}ê°œì˜ ìœ íš¨í•œ ë¼ì´ë¸Œ ë°©ì†¡ ë§í¬ ë°œê²¬")
        
        # í…ŒìŠ¤íŠ¸ 3: ì²« ë²ˆì§¸ ë¼ì´ë¸Œ ë°©ì†¡ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        if found_links:
            test_url = found_links[0]
            if test_url.startswith('/'):
                test_url = f"https://view.shoppinglive.naver.com{test_url}"
            
            logger.info(f"\ní…ŒìŠ¤íŠ¸ 3: ë¼ì´ë¸Œ ë°©ì†¡ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘")
            logger.info(f"   URL: {test_url}")
            
            driver.get(test_url)
            time.sleep(3)
            
            # í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ
            page_html = driver.page_source
            page_soup = BeautifulSoup(page_html, 'html.parser')
            
            # ì œëª© ì°¾ê¸°
            title_selectors = [
                'h1',
                '.title',
                '[class*="title"]',
                'meta[property="og:title"]',
            ]
            
            title = None
            for selector in title_selectors:
                if selector.startswith('meta'):
                    element = page_soup.select_one(selector)
                    if element:
                        title = element.get('content')
                        break
                else:
                    element = page_soup.select_one(selector)
                    if element:
                        title = element.get_text(strip=True)
                        break
            
            logger.info(f"   ì œëª©: {title or 'ì°¾ì„ ìˆ˜ ì—†ìŒ'}")
            
            # ë¸Œëœë“œ ì •ë³´ ì°¾ê¸°
            brand_selectors = [
                '.brand',
                '[class*="brand"]',
                'meta[property="og:site_name"]',
            ]
            
            brand = None
            for selector in brand_selectors:
                if selector.startswith('meta'):
                    element = page_soup.select_one(selector)
                    if element:
                        brand = element.get('content')
                        break
                else:
                    element = page_soup.select_one(selector)
                    if element:
                        brand = element.get_text(strip=True)
                        break
            
            logger.info(f"   ë¸Œëœë“œ: {brand or 'ì°¾ì„ ìˆ˜ ì—†ìŒ'}")
            
            if title:
                logger.info("   âœ… ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì„±ê³µ!")
            else:
                logger.warning("   âš ï¸ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨ (ì œëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ)")
        else:
            logger.warning("\ní…ŒìŠ¤íŠ¸ 3: ê±´ë„ˆëœ€ (ë¼ì´ë¸Œ ë°©ì†¡ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ)")
        
        # ê²°ê³¼ ìš”ì•½
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        logger.info("=" * 80)
        logger.info(f"âœ… ChromeDriver ì´ˆê¸°í™”: ì„±ê³µ")
        logger.info(f"âœ… ë©”ì¸ í˜ì´ì§€ ì ‘ì†: ì„±ê³µ")
        logger.info(f"{'âœ…' if found_links else 'âŒ'} ë¼ì´ë¸Œ ë°©ì†¡ ê²€ìƒ‰: {len(found_links)}ê°œ ë°œê²¬")
        logger.info(f"{'âœ…' if title else 'âŒ'} ìƒì„¸ ì •ë³´ ìˆ˜ì§‘: {'ì„±ê³µ' if title else 'ì‹¤íŒ¨'}")
        logger.info("=" * 80)
        
        if found_links and title:
            logger.info("\nâœ… ì‹¤ì œ í¬ë¡¤ë§ ê°€ëŠ¥!")
            logger.info("   í¬ë¡¤ëŸ¬ë¥¼ ìˆ˜ì •í•˜ì—¬ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return True
        else:
            logger.warning("\nâš ï¸ í¬ë¡¤ë§ ê°œì„  í•„ìš”")
            logger.warning("   ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ê³  ì„ íƒìë¥¼ ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤.")
            return False
        
    except Exception as e:
        logger.error(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)
        return False
    finally:
        if driver:
            driver.quit()
            logger.info("\nChromeDriver ì¢…ë£Œ")


if __name__ == "__main__":
    logger.info("ì‹¤ì œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    logger.info("ì´ í…ŒìŠ¤íŠ¸ëŠ” ì•½ 30ì´ˆ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤.\n")
    
    success = test_naver_crawling()
    
    sys.exit(0 if success else 1)
