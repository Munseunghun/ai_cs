#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ë„¤ì´ë²„ ì‡¼í•‘ ì „ì‹œ í˜ì´ì§€ í¬ë¡¤ëŸ¬
ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì‡¼í•‘ìŠ¤í† ë¦¬ ì „ì‹œ í˜ì´ì§€ì—ì„œ í–‰ì‚¬ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

ìˆ˜ì§‘ í•­ëª©:
1. í”Œë«í¼ëª…: ë„¤ì´ë²„ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´
2. ë¸Œëœë“œëª…
3. í–‰ì‚¬ íƒ€ì´í‹€
4. í–‰ì‚¬ ì¼ì
5. í˜œíƒ ì •ë³´ (ê¸ˆì•¡ëŒ€ë³„ í˜œíƒ, ì¿ í°)
6. ìƒí’ˆ ì •ë³´
"""

import os
import sys
import time
import re
import json
from datetime import datetime
from typing import Dict, List, Optional
from urllib.parse import urlparse, parse_qs

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from supabase import create_client, Client

# ë¡œê¹… ì„¤ì •
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('naver_shopping_crawler.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


class NaverShoppingCrawler:
    """ë„¤ì´ë²„ ì‡¼í•‘ ì „ì‹œ í˜ì´ì§€ í¬ë¡¤ëŸ¬"""
    
    def __init__(self):
        """í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”"""
        self.driver = None
        self.supabase: Optional[Client] = None
        self._init_supabase()
    
    def _init_supabase(self):
        """Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            _v_url = os.getenv('SUPABASE_URL')
            _v_key = os.getenv('SUPABASE_ANON_KEY')
            
            if not _v_url or not _v_key:
                logger.warning("âš ï¸ Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return
            
            self.supabase = create_client(_v_url, _v_key)
            logger.info("âœ… Supabase ì—°ê²° ì„±ê³µ")
        except Exception as e:
            logger.error(f"âŒ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")
    
    def _init_driver(self):
        """Selenium WebDriver ì´ˆê¸°í™”"""
        try:
            _v_chrome_options = Options()
            _v_chrome_options.add_argument('--headless')
            _v_chrome_options.add_argument('--no-sandbox')
            _v_chrome_options.add_argument('--disable-dev-shm-usage')
            _v_chrome_options.add_argument('--disable-gpu')
            _v_chrome_options.add_argument('--window-size=1920,1080')
            _v_chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            self.driver = webdriver.Chrome(
                service=Service(ChromeDriverManager().install()),
                options=_v_chrome_options
            )
            logger.info("âœ… WebDriver ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            logger.error(f"âŒ WebDriver ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def crawl(self, p_url: str, p_brand: str = "ì•„ì´ì˜¤í˜") -> Dict:
        """
        ë„¤ì´ë²„ ì‡¼í•‘ ì „ì‹œ í˜ì´ì§€ í¬ë¡¤ë§
        
        Args:
            p_url: í¬ë¡¤ë§í•  URL
            p_brand: ë¸Œëœë“œëª…
        
        Returns:
            ìˆ˜ì§‘ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ” ë„¤ì´ë²„ ì‡¼í•‘ ì „ì‹œ í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘")
        logger.info(f"{'='*80}")
        logger.info(f"ğŸ“ URL: {p_url}")
        logger.info(f"ğŸ·ï¸  ë¸Œëœë“œ: {p_brand}")
        
        try:
            # WebDriver ì´ˆê¸°í™”
            if not self.driver:
                self._init_driver()
            
            # í˜ì´ì§€ ë¡œë“œ
            logger.info("\nğŸ“„ í˜ì´ì§€ ë¡œë”© ì¤‘...")
            self.driver.get(p_url)
            time.sleep(5)  # ë™ì  ì½˜í…ì¸  ë¡œë”© ëŒ€ê¸°
            
            # í˜ì´ì§€ ìŠ¤í¬ë¡¤ (lazy loading ì½˜í…ì¸  ë¡œë“œ)
            logger.info("ğŸ“œ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì¤‘...")
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(3)
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight/2);")
            time.sleep(2)
            self.driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(2)
            
            # ë°ì´í„° ìˆ˜ì§‘
            _v_data = {
                'platform': 'ë„¤ì´ë²„ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´',
                'brand': p_brand,
                'url': p_url,
                'event_id': self._extract_event_id(p_url),
                'title': self._collect_title(),
                'date_info': self._collect_date(),
                'benefits': self._collect_benefits(),
                'coupons': self._collect_coupons(),
                'products': self._collect_products(),
                'collected_at': datetime.now().isoformat()
            }
            
            logger.info(f"\nâœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
            logger.info(f"   íƒ€ì´í‹€: {_v_data['title']}")
            logger.info(f"   í–‰ì‚¬ ì¼ì: {_v_data['date_info']}")
            logger.info(f"   í˜œíƒ: {len(_v_data['benefits'])}ê°œ")
            logger.info(f"   ì¿ í°: {len(_v_data['coupons'])}ê°œ")
            logger.info(f"   ìƒí’ˆ: {len(_v_data['products'])}ê°œ")
            
            return _v_data
            
        except Exception as e:
            logger.error(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return {}
    
    def _extract_event_id(self, p_url: str) -> str:
        """URLì—ì„œ ì´ë²¤íŠ¸ ID ì¶”ì¶œ"""
        try:
            _v_parsed = urlparse(p_url)
            _v_params = parse_qs(_v_parsed.query)
            _v_event_id = _v_params.get('id', [''])[0]
            return f"NAVER_SHOPPING_{_v_event_id}" if _v_event_id else f"NAVER_SHOPPING_{int(time.time())}"
        except:
            return f"NAVER_SHOPPING_{int(time.time())}"
    
    def _collect_title(self) -> str:
        """
        í–‰ì‚¬ íƒ€ì´í‹€ ìˆ˜ì§‘
        __PRELOADED_STATE__ JSONì—ì„œ íƒ€ì´í‹€ íŒŒì‹±
        """
        logger.info("\nğŸ“Œ [1] í–‰ì‚¬ íƒ€ì´í‹€ ìˆ˜ì§‘ ì¤‘...")
        
        try:
            # 1. JSON ë°ì´í„°ì—ì„œ íƒ€ì´í‹€ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
            _v_state_data = self._extract_preloaded_state()
            
            if _v_state_data:
                # shoppingStory.A.detail.postTitleì—ì„œ íƒ€ì´í‹€ ì¶”ì¶œ
                _v_shopping_story = _v_state_data.get('shoppingStory', {}).get('A', {})
                _v_detail = _v_shopping_story.get('detail', {})
                _v_post_title = _v_detail.get('postTitle', '')
                
                if _v_post_title:
                    logger.info(f"   âœ… JSONì—ì„œ íƒ€ì´í‹€ ë°œê²¬: {_v_post_title}")
                    return _v_post_title.strip()
            
            # 2. JSONì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš°, HTML íŒŒì‹± (í´ë°±)
            logger.info("   â„¹ï¸ HTMLì—ì„œ íƒ€ì´í‹€ ê²€ìƒ‰ ì¤‘...")
            
            _v_soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            
            # ë°©ë²• 1: í˜ì´ì§€ íƒ€ì´í‹€
            _v_page_title = self.driver.title
            if _v_page_title and 'ì‡¼í•‘ìŠ¤í† ë¦¬' not in _v_page_title:
                logger.info(f"   âœ… íƒ€ì´í‹€ ë°œê²¬: {_v_page_title}")
                return _v_page_title.strip()
            
            # ë°©ë²• 2: í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ ë§¤ì¹­
            _v_all_text = _v_soup.get_text()
            
            # "ì•„ì´ì˜¤í˜ XMDìŠ¤í…œ3" ê°™ì€ íŒ¨í„´ ì°¾ê¸°
            _v_title_patterns = [
                r'ì•„ì´ì˜¤í˜\s+[A-Z]+[ê°€-í£\s]+',
                r'[ê°€-í£]+\s+ê¸°íšì „',
                r'[ê°€-í£]+\s+í”„ë¡œëª¨ì…˜',
                r'[ê°€-í£]+\s+ì´ë²¤íŠ¸'
            ]
            
            for pattern in _v_title_patterns:
                _v_match = re.search(pattern, _v_all_text)
                if _v_match:
                    _v_title = _v_match.group(0).strip()
                    logger.info(f"   âœ… íƒ€ì´í‹€ ë°œê²¬: {_v_title}")
                    return _v_title
            
            # ë°©ë²• 3: h1, h2 íƒœê·¸
            for tag in ['h1', 'h2', 'h3']:
                _v_heading = _v_soup.find(tag)
                if _v_heading:
                    _v_text = _v_heading.get_text(strip=True)
                    if _v_text and len(_v_text) > 5:
                        logger.info(f"   âœ… íƒ€ì´í‹€ ë°œê²¬: {_v_text}")
                        return _v_text
            
            logger.warning("   âš ï¸ íƒ€ì´í‹€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return "ì œëª© ì—†ìŒ"
            
        except Exception as e:
            logger.error(f"   âŒ íƒ€ì´í‹€ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return "ì œëª© ì—†ìŒ"
    
    def _collect_date(self) -> str:
        """í–‰ì‚¬ ì¼ì ìˆ˜ì§‘"""
        logger.info("\nğŸ“… [2] í–‰ì‚¬ ì¼ì ìˆ˜ì§‘ ì¤‘...")
        
        try:
            _v_soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            _v_all_text = _v_soup.get_text()
            
            # ë‚ ì§œ íŒ¨í„´ ì°¾ê¸°
            _v_date_patterns = [
                r'\d{2,4}[./-]\d{1,2}[./-]\d{1,2}\s*~\s*\d{2,4}[./-]\d{1,2}[./-]\d{1,2}',  # ê¸°ê°„
                r'\d{2,4}[./-]\d{1,2}[./-]\d{1,2}',  # ë‹¨ì¼ ë‚ ì§œ
            ]
            
            for pattern in _v_date_patterns:
                _v_matches = re.findall(pattern, _v_all_text)
                if _v_matches:
                    _v_date = _v_matches[0]
                    logger.info(f"   âœ… í–‰ì‚¬ ì¼ì ë°œê²¬: {_v_date}")
                    return _v_date
            
            logger.warning("   âš ï¸ í–‰ì‚¬ ì¼ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return "ë‚ ì§œ ì •ë³´ ì—†ìŒ"
            
        except Exception as e:
            logger.error(f"   âŒ í–‰ì‚¬ ì¼ì ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return "ë‚ ì§œ ì •ë³´ ì—†ìŒ"
    
    def _extract_preloaded_state(self) -> Dict:
        """
        í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ __PRELOADED_STATE__ JSON ë°ì´í„° ì¶”ì¶œ
        
        Returns:
            íŒŒì‹±ëœ JSON ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        try:
            _v_page_source = self.driver.page_source
            
            # __PRELOADED_STATE__ íŒ¨í„´ ì°¾ê¸°
            _v_pattern = r'window\.__PRELOADED_STATE__=({.*?})</script>'
            _v_match = re.search(_v_pattern, _v_page_source, re.DOTALL)
            
            if _v_match:
                _v_json_str = _v_match.group(1)
                _v_data = json.loads(_v_json_str)
                logger.info("   âœ… __PRELOADED_STATE__ JSON íŒŒì‹± ì„±ê³µ")
                return _v_data
            else:
                logger.warning("   âš ï¸ __PRELOADED_STATE__ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {}
                
        except json.JSONDecodeError as e:
            logger.error(f"   âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {}
        except Exception as e:
            logger.error(f"   âŒ __PRELOADED_STATE__ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}
    
    def _collect_benefits(self) -> List[Dict]:
        """
        í˜œíƒ ì •ë³´ ìˆ˜ì§‘ (ê¸ˆì•¡ëŒ€ë³„ í˜œíƒ)
        __PRELOADED_STATE__ JSONì—ì„œ benefitsV2 ë°ì´í„° íŒŒì‹±
        """
        logger.info("\nğŸ [3] í˜œíƒ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        
        _v_benefits = []
        
        try:
            # 1. JSON ë°ì´í„°ì—ì„œ í˜œíƒ ì •ë³´ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
            _v_state_data = self._extract_preloaded_state()
            
            if _v_state_data:
                # benefitsV2.A ë°°ì—´ì—ì„œ í˜œíƒ ì •ë³´ ì¶”ì¶œ
                _v_benefits_v2 = _v_state_data.get('benefitsV2', {}).get('A', [])
                
                if _v_benefits_v2:
                    logger.info(f"   ğŸ“Š JSONì—ì„œ {len(_v_benefits_v2)}ê°œì˜ í˜œíƒ ë°œê²¬")
                    
                    for benefit_item in _v_benefits_v2:
                        _v_policy = benefit_item.get('policy', {})
                        
                        # í˜œíƒ ì •ì±… ì •ë³´ ì¶”ì¶œ
                        _v_benefit_name = _v_policy.get('benefitPolicyName', '')
                        _v_benefit_value = _v_policy.get('benefitValue', 0)
                        _v_min_order_amount = _v_policy.get('minOrderAmount', 0)
                        _v_benefit_unit = _v_policy.get('benefitUnit', 'FIX')
                        _v_coupon_kind = _v_policy.get('benefitCouponPolicy', {}).get('couponKind', '')
                        
                        # í˜œíƒ ì¡°ê±´ í…ìŠ¤íŠ¸ ìƒì„±
                        if _v_min_order_amount > 0:
                            _v_condition = f"{_v_min_order_amount:,}ì› ì´ìƒ êµ¬ë§¤ì‹œ"
                        else:
                            _v_condition = "ì „ êµ¬ë§¤ ê³ ê°"
                        
                        # í˜œíƒ ë‚´ìš© í…ìŠ¤íŠ¸ ìƒì„±
                        if _v_benefit_unit == 'FIX':
                            _v_benefit_text = f"{_v_benefit_value:,}ì› í• ì¸"
                        elif _v_benefit_unit == 'PERCENT':
                            _v_benefit_text = f"{_v_benefit_value}% í• ì¸"
                        else:
                            _v_benefit_text = f"{_v_benefit_value} í• ì¸"
                        
                        # ì¿ í° ì¢…ë¥˜ ì¶”ê°€
                        if _v_coupon_kind:
                            _v_benefit_text += f" ({_v_coupon_kind} ì¿ í°)"
                        
                        _v_benefits.append({
                            'type': 'ê¸ˆì•¡ëŒ€ë³„ í˜œíƒ',
                            'condition': _v_condition,
                            'benefit': f"{_v_benefit_name} - {_v_benefit_text}",
                            'benefit_value': _v_benefit_value,
                            'min_order_amount': _v_min_order_amount,
                            'source': 'JSON'
                        })
                    
                    logger.info(f"   âœ… JSONì—ì„œ í˜œíƒ {len(_v_benefits)}ê°œ ìˆ˜ì§‘")
                else:
                    logger.info("   â„¹ï¸ JSONì— benefitsV2 ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # 2. JSONì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°, HTML í…ìŠ¤íŠ¸ íŒŒì‹± (í´ë°±)
            if not _v_benefits:
                logger.info("   â„¹ï¸ HTML í…ìŠ¤íŠ¸ì—ì„œ í˜œíƒ ì •ë³´ ê²€ìƒ‰ ì¤‘...")
                
                _v_soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                _v_all_text = _v_soup.get_text()
                
                # ê¸ˆì•¡ëŒ€ë³„ í˜œíƒ íŒ¨í„´
                _v_price_patterns = [
                    r'(\d+ë§Œ?\s*ì›)\s*ì´ìƒ\s*êµ¬ë§¤\s*ì‹œ?\s*([^.]+)',
                    r'ì „\s*êµ¬ë§¤\s*ê³ ê°\s*([^.]+)',
                ]
                
                for pattern in _v_price_patterns:
                    _v_matches = re.findall(pattern, _v_all_text)
                    for match in _v_matches:
                        if isinstance(match, tuple):
                            if len(match) == 2:
                                _v_benefits.append({
                                    'type': 'ê¸ˆì•¡ëŒ€ë³„ í˜œíƒ',
                                    'condition': match[0].strip(),
                                    'benefit': match[1].strip()[:200],
                                    'source': 'HTML'
                                })
                            else:
                                _v_benefits.append({
                                    'type': 'ê¸ˆì•¡ëŒ€ë³„ í˜œíƒ',
                                    'condition': 'ì „ êµ¬ë§¤ ê³ ê°',
                                    'benefit': match[0].strip()[:200],
                                    'source': 'HTML'
                                })
                
                logger.info(f"   âœ… HTMLì—ì„œ í˜œíƒ {len(_v_benefits)}ê°œ ìˆ˜ì§‘")
            
            # ê²°ê³¼ ì¶œë ¥
            for idx, benefit in enumerate(_v_benefits, 1):
                logger.info(f"      [{idx}] {benefit['condition']}: {benefit['benefit'][:80]}")
            
            return _v_benefits
            
        except Exception as e:
            logger.error(f"   âŒ í˜œíƒ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _collect_coupons(self) -> List[Dict]:
        """
        ì¿ í° ì •ë³´ ìˆ˜ì§‘
        __PRELOADED_STATE__ JSONì—ì„œ benefitsV2 ë°ì´í„° íŒŒì‹±
        """
        logger.info("\nğŸ« [4] ì¿ í° ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        
        _v_coupons = []
        
        try:
            # 1. JSON ë°ì´í„°ì—ì„œ ì¿ í° ì •ë³´ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
            _v_state_data = self._extract_preloaded_state()
            
            if _v_state_data:
                # benefitsV2.A ë°°ì—´ì—ì„œ ì¿ í° ì •ë³´ ì¶”ì¶œ
                _v_benefits_v2 = _v_state_data.get('benefitsV2', {}).get('A', [])
                
                if _v_benefits_v2:
                    logger.info(f"   ğŸ“Š JSONì—ì„œ {len(_v_benefits_v2)}ê°œì˜ ì¿ í° ì •ì±… ë°œê²¬")
                    
                    for benefit_item in _v_benefits_v2:
                        _v_policy = benefit_item.get('policy', {})
                        _v_coupon_policy = _v_policy.get('benefitCouponPolicy', {})
                        
                        # ì¿ í°ì¸ ê²½ìš°ë§Œ ì²˜ë¦¬
                        if _v_policy.get('benefitKind') == 'COUPON':
                            _v_coupon_name = _v_policy.get('benefitPolicyName', '')
                            _v_coupon_kind = _v_coupon_policy.get('couponKind', '')
                            _v_benefit_value = _v_policy.get('benefitValue', 0)
                            _v_min_order_amount = _v_coupon_policy.get('minOrderAmount', 0)
                            _v_benefit_unit = _v_policy.get('benefitUnit', 'FIX')
                            
                            # ì¿ í° ì„¤ëª… ìƒì„±
                            _v_description_parts = []
                            
                            if _v_min_order_amount > 0:
                                _v_description_parts.append(f"{_v_min_order_amount:,}ì› ì´ìƒ êµ¬ë§¤ì‹œ")
                            
                            if _v_benefit_unit == 'FIX':
                                _v_description_parts.append(f"{_v_benefit_value:,}ì› í• ì¸")
                            elif _v_benefit_unit == 'PERCENT':
                                _v_description_parts.append(f"{_v_benefit_value}% í• ì¸")
                            
                            if _v_coupon_kind:
                                _v_description_parts.append(f"({_v_coupon_kind})")
                            
                            _v_coupons.append({
                                'type': 'ì¿ í°',
                                'name': _v_coupon_name,
                                'description': ' '.join(_v_description_parts),
                                'benefit_value': _v_benefit_value,
                                'min_order_amount': _v_min_order_amount,
                                'coupon_kind': _v_coupon_kind,
                                'source': 'JSON'
                            })
                    
                    logger.info(f"   âœ… JSONì—ì„œ ì¿ í° {len(_v_coupons)}ê°œ ìˆ˜ì§‘")
                else:
                    logger.info("   â„¹ï¸ JSONì— benefitsV2 ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # 2. JSONì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°, HTML í…ìŠ¤íŠ¸ íŒŒì‹± (í´ë°±)
            if not _v_coupons:
                logger.info("   â„¹ï¸ HTML í…ìŠ¤íŠ¸ì—ì„œ ì¿ í° ì •ë³´ ê²€ìƒ‰ ì¤‘...")
                
                _v_soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                _v_all_text = _v_soup.get_text()
                
                # ì¿ í° ê´€ë ¨ í…ìŠ¤íŠ¸ ì°¾ê¸°
                _v_coupon_keywords = ['ì¿ í°', 'COUPON']
                _v_lines = _v_all_text.split('\n')
                
                for line in _v_lines:
                    for keyword in _v_coupon_keywords:
                        if keyword in line:
                            _v_clean_line = line.strip()
                            if _v_clean_line and len(_v_clean_line) > 3 and len(_v_clean_line) < 200:
                                _v_coupons.append({
                                    'type': 'ì¿ í°',
                                    'name': _v_clean_line,
                                    'source': 'HTML'
                                })
                
                # ì¤‘ë³µ ì œê±°
                _v_unique_coupons = []
                _v_seen = set()
                for coupon in _v_coupons:
                    if coupon['name'] not in _v_seen:
                        _v_seen.add(coupon['name'])
                        _v_unique_coupons.append(coupon)
                
                _v_coupons = _v_unique_coupons
                logger.info(f"   âœ… HTMLì—ì„œ ì¿ í° {len(_v_coupons)}ê°œ ìˆ˜ì§‘")
            
            # ê²°ê³¼ ì¶œë ¥
            for idx, coupon in enumerate(_v_coupons, 1):
                _v_display_name = coupon.get('name', '')[:80]
                _v_display_desc = coupon.get('description', '')
                if _v_display_desc:
                    logger.info(f"      [{idx}] {_v_display_name} - {_v_display_desc}")
                else:
                    logger.info(f"      [{idx}] {_v_display_name}")
            
            return _v_coupons
            
        except Exception as e:
            logger.error(f"   âŒ ì¿ í° ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _collect_products(self) -> List[Dict]:
        """
        ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘
        __PRELOADED_STATE__ JSONì—ì„œ ìƒí’ˆ ë°ì´í„° íŒŒì‹±
        """
        logger.info("\nğŸ›ï¸  [5] ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        
        _v_products = []
        
        try:
            # 1. JSON ë°ì´í„°ì—ì„œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
            _v_state_data = self._extract_preloaded_state()
            
            if _v_state_data:
                # shoppingStory.A.detail.relationProductSectionsì—ì„œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
                _v_shopping_story = _v_state_data.get('shoppingStory', {}).get('A', {})
                _v_detail = _v_shopping_story.get('detail', {})
                _v_product_sections = _v_detail.get('relationProductSections', [])
                
                if _v_product_sections:
                    logger.info(f"   ğŸ“Š JSONì—ì„œ {len(_v_product_sections)}ê°œì˜ ìƒí’ˆ ì„¹ì…˜ ë°œê²¬")
                    
                    for section in _v_product_sections:
                        _v_simple_products = section.get('simpleProducts', [])
                        
                        for product in _v_simple_products:
                            _v_product_name = product.get('name', '') or product.get('dispName', '')
                            _v_product_url = f"https://brand.naver.com{product.get('channel', {}).get('url', '')}/products/{product.get('id', '')}"
                            _v_sale_price = product.get('salePrice', 0)
                            _v_benefits_view = product.get('benefitsView', {})
                            _v_discounted_price = _v_benefits_view.get('discountedSalePrice', 0)
                            _v_discount_ratio = _v_benefits_view.get('discountedRatio', 0)
                            
                            if _v_product_name:
                                _v_products.append({
                                    'product_order': len(_v_products) + 1,
                                    'product_name': _v_product_name[:200],
                                    'product_url': _v_product_url,
                                    'original_price': _v_sale_price if _v_sale_price > 0 else None,
                                    'sale_price': _v_discounted_price if _v_discounted_price > 0 else None,
                                    'discount_rate': _v_discount_ratio if _v_discount_ratio > 0 else None,
                                    'source': 'JSON'
                                })
                    
                    logger.info(f"   âœ… JSONì—ì„œ ìƒí’ˆ {len(_v_products)}ê°œ ìˆ˜ì§‘")
                else:
                    logger.info("   â„¹ï¸ JSONì— ìƒí’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # 2. JSONì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°, Seleniumìœ¼ë¡œ ìƒí’ˆ ì°¾ê¸° (í´ë°±)
            if not _v_products:
                logger.info("   â„¹ï¸ Seleniumìœ¼ë¡œ ìƒí’ˆ ì •ë³´ ê²€ìƒ‰ ì¤‘...")
                
                try:
                    # ìƒí’ˆ ë§í¬ ì°¾ê¸° (a íƒœê·¸ ì¤‘ ìƒí’ˆ URL íŒ¨í„´)
                    _v_product_links = self.driver.find_elements(By.CSS_SELECTOR, 'a[href*="/products/"]')
                    
                    logger.info(f"   ğŸ“¦ ìƒí’ˆ ë§í¬ {len(_v_product_links)}ê°œ ë°œê²¬")
                    
                    # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ set
                    _v_seen_urls = set()
                    
                    for idx, link in enumerate(_v_product_links[:20], 1):  # ìµœëŒ€ 20ê°œ
                        try:
                            _v_url = link.get_attribute('href')
                            if not _v_url or _v_url in _v_seen_urls:
                                continue
                            
                            _v_seen_urls.add(_v_url)
                            
                            # ìƒí’ˆëª… ì°¾ê¸°
                            _v_name = link.text.strip()
                            if not _v_name or len(_v_name) < 3:
                                # ë¶€ëª¨ ìš”ì†Œì—ì„œ í…ìŠ¤íŠ¸ ì°¾ê¸°
                                _v_parent = link.find_element(By.XPATH, '..')
                                _v_name = _v_parent.text.strip()
                            
                            if _v_name and len(_v_name) > 3:
                                _v_products.append({
                                    'product_order': len(_v_products) + 1,
                                    'product_name': _v_name[:200],
                                    'product_url': _v_url,
                                    'original_price': None,
                                    'sale_price': None,
                                    'discount_rate': None,
                                    'source': 'HTML'
                                })
                        
                        except Exception as e:
                            logger.debug(f"      ìƒí’ˆ {idx} íŒŒì‹± ì‹¤íŒ¨: {e}")
                            continue
                    
                except Exception as e:
                    logger.warning(f"   âš ï¸ Seleniumìœ¼ë¡œ ìƒí’ˆ ì°¾ê¸° ì‹¤íŒ¨: {e}")
                
                logger.info(f"   âœ… HTMLì—ì„œ ìƒí’ˆ {len(_v_products)}ê°œ ìˆ˜ì§‘")
            
            # ê²°ê³¼ ì¶œë ¥
            for idx, product in enumerate(_v_products[:10], 1):  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
                _v_price_info = ""
                if product.get('sale_price'):
                    _v_price_info = f" - {product['sale_price']:,}ì›"
                    if product.get('discount_rate'):
                        _v_price_info += f" ({product['discount_rate']}% í• ì¸)"
                
                logger.info(f"      [{idx}] {product['product_name'][:60]}{_v_price_info}")
            
            if len(_v_products) > 10:
                logger.info(f"      ... ì™¸ {len(_v_products) - 10}ê°œ ìƒí’ˆ")
            
            return _v_products
            
        except Exception as e:
            logger.error(f"   âŒ ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def save_to_supabase(self, p_data: Dict) -> bool:
        """
        ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ Supabaseì— ì €ì¥
        
        Args:
            p_data: ìˆ˜ì§‘ëœ ë°ì´í„°
        
        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        if not self.supabase:
            logger.warning("âš ï¸ Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            logger.info(f"\n{'='*80}")
            logger.info("ğŸ’¾ Supabaseì— ë°ì´í„° ì €ì¥ ì¤‘...")
            logger.info(f"{'='*80}")
            
            # 1. live_broadcasts í…Œì´ë¸”ì— ì €ì¥
            _v_live_data = {
                'live_id': p_data['event_id'],
                'channel_code': 'NAVER_SHOPPING',
                'platform_name': p_data['platform'],
                'brand_name': p_data['brand'],
                'live_title_customer': p_data['title'],
                'live_title_cs': p_data['title'],
                'source_url': p_data['url'],
                'broadcast_date': datetime.now().date().isoformat(),
                'broadcast_type': 'EXHIBITION',  # ì „ì‹œ/ì´ë²¤íŠ¸ í˜ì´ì§€ êµ¬ë¶„
                'status': 'ACTIVE',  # ê¸°ë³¸ê°’
                'collected_at': datetime.now().isoformat()
            }
            
            # ê¸°ì¡´ ë°ì´í„° í™•ì¸
            _v_existing = self.supabase.table('live_broadcasts').select('*').eq('live_id', p_data['event_id']).execute()
            
            if _v_existing.data:
                # ì—…ë°ì´íŠ¸
                self.supabase.table('live_broadcasts').update(_v_live_data).eq('live_id', p_data['event_id']).execute()
                logger.info(f"   âœ… live_broadcasts ì—…ë°ì´íŠ¸: {p_data['event_id']}")
            else:
                # ì‚½ì…
                self.supabase.table('live_broadcasts').insert(_v_live_data).execute()
                logger.info(f"   âœ… live_broadcasts ì €ì¥: {p_data['event_id']}")
            
            # 2. ìƒí’ˆ ì •ë³´ ì €ì¥
            if p_data['products']:
                for product in p_data['products']:
                    _v_product_data = {
                        'live_id': p_data['event_id'],
                        'product_order': product.get('product_order', 0),
                        'product_name': product.get('product_name'),
                        'original_price': product.get('original_price'),
                        'sale_price': product.get('sale_price'),
                        'discount_rate': product.get('discount_rate'),
                        'product_url': product.get('product_url')
                    }
                    try:
                        self.supabase.table('live_products').insert(_v_product_data).execute()
                    except Exception as e:
                        logger.debug(f"   ìƒí’ˆ ì €ì¥ ì‹¤íŒ¨: {e}")
                
                logger.info(f"   âœ… ìƒí’ˆ {len(p_data['products'])}ê°œ ì €ì¥")
            
            # 3. í˜œíƒ ì •ë³´ë¥¼ live_benefits í…Œì´ë¸”ì— ì €ì¥
            # ë¨¼ì € ê¸°ì¡´ í˜œíƒ ë°ì´í„° ì‚­ì œ (ì¤‘ë³µ ë°©ì§€)
            try:
                self.supabase.table('live_benefits').delete().eq('live_id', p_data['event_id']).eq('benefit_type', 'í• ì¸').execute()
            except Exception as e:
                logger.debug(f"   ê¸°ì¡´ í˜œíƒ ì‚­ì œ ì‹¤íŒ¨: {e}")
            
            _v_benefit_count = 0
            for idx, benefit in enumerate(p_data['benefits'], 1):
                try:
                    _v_benefit_data = {
                        'live_id': p_data['event_id'],
                        'benefit_type': 'í• ì¸',
                        'benefit_name': benefit.get('benefit', '')[:500],
                        'benefit_detail': f"í• ì¸ ê¸ˆì•¡: {benefit.get('benefit_value', 0):,}ì›\nìµœì†Œ êµ¬ë§¤: {benefit.get('min_order_amount', 0):,}ì›",
                        'benefit_condition': benefit.get('condition', ''),
                        'benefit_valid_period': p_data.get('date_info', '')
                    }
                    
                    # ì‚½ì…
                    self.supabase.table('live_benefits').insert(_v_benefit_data).execute()
                    _v_benefit_count += 1
                except Exception as e:
                    logger.debug(f"   í˜œíƒ ì €ì¥ ì‹¤íŒ¨ (idx={idx}): {e}")
            
            logger.info(f"   âœ… í˜œíƒ {_v_benefit_count}ê°œ ì €ì¥")
            
            # 4. ì¿ í° ì •ë³´ë¥¼ live_benefits í…Œì´ë¸”ì— ì €ì¥
            # ë¨¼ì € ê¸°ì¡´ ì¿ í° ë°ì´í„° ì‚­ì œ (ì¤‘ë³µ ë°©ì§€)
            try:
                self.supabase.table('live_benefits').delete().eq('live_id', p_data['event_id']).eq('benefit_type', 'ì¿ í°').execute()
            except Exception as e:
                logger.debug(f"   ê¸°ì¡´ ì¿ í° ì‚­ì œ ì‹¤íŒ¨: {e}")
            
            _v_coupon_count = 0
            for idx, coupon in enumerate(p_data['coupons'], 1):
                try:
                    _v_coupon_data = {
                        'live_id': p_data['event_id'],
                        'benefit_type': 'ì¿ í°',
                        'benefit_name': coupon.get('name', '')[:500],
                        'benefit_detail': coupon.get('description', ''),
                        'benefit_condition': f"ìµœì†Œ êµ¬ë§¤: {coupon.get('min_order_amount', 0):,}ì›\nì¿ í° ì¢…ë¥˜: {coupon.get('coupon_kind', '')}",
                        'benefit_valid_period': p_data.get('date_info', '')
                    }
                    
                    # ì‚½ì…
                    self.supabase.table('live_benefits').insert(_v_coupon_data).execute()
                    _v_coupon_count += 1
                except Exception as e:
                    logger.debug(f"   ì¿ í° ì €ì¥ ì‹¤íŒ¨ (idx={idx}): {e}")
            
            logger.info(f"   âœ… ì¿ í° {_v_coupon_count}ê°œ ì €ì¥")
            
            # 5. ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ (live_title_csì— ìš”ì•½ ì •ë³´ ì €ì¥)
            _v_metadata_str = f"{p_data['title']} | í˜œíƒ: {len(p_data['benefits'])}ê°œ | ì¿ í°: {len(p_data['coupons'])}ê°œ"
            self.supabase.table('live_broadcasts').update({
                'live_title_cs': _v_metadata_str[:500]
            }).eq('live_id', p_data['event_id']).execute()
            
            logger.info(f"   âœ… ë©”íƒ€ë°ì´í„° ì €ì¥")
            logger.info(f"\n{'='*80}")
            logger.info("âœ… Supabase ì €ì¥ ì™„ë£Œ!")
            logger.info(f"{'='*80}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Supabase ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.driver:
            self.driver.quit()
            logger.info("ğŸ”š WebDriver ì¢…ë£Œ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ìƒ˜í”Œ URL
    _v_url = "https://brand.naver.com/iope/shoppingstory/detail?id=5002337684"
    _v_brand = "ì•„ì´ì˜¤í˜"
    
    _v_crawler = NaverShoppingCrawler()
    
    try:
        # í¬ë¡¤ë§ ì‹¤í–‰
        _v_data = _v_crawler.crawl(_v_url, _v_brand)
        
        if _v_data:
            # Supabaseì— ì €ì¥
            _v_crawler.save_to_supabase(_v_data)
            
            # JSON íŒŒì¼ë¡œë„ ì €ì¥
            _v_filename = f"naver_shopping_{_v_data['event_id']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(_v_filename, 'w', encoding='utf-8') as f:
                json.dump(_v_data, f, ensure_ascii=False, indent=2)
            logger.info(f"\nğŸ“ JSON íŒŒì¼ ì €ì¥: {_v_filename}")
    
    finally:
        _v_crawler.close()


if __name__ == "__main__":
    main()
