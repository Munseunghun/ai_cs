# 데이터 수집 스케줄러 검증 보고서

작성일: 2025-12-04
작성자: AI Assistant

---

## 📋 검증 요약

### ✅ 설정 확인 완료

#### 1. 플랫폼 설정 (10개)
- ✅ **설정 파일 위치**: `/Users/amore/ai_cs 시스템/crawler/config/platforms.json`
- ✅ **활성 플랫폼 수**: **10개** (모두 `isActive: true`)

**플랫폼 목록**:
1. 네이버 (NAVER)
2. 카카오 (KAKAO)
3. 11번가 (11ST)
4. G마켓 (GMARKET)
5. 올리브영 (OLIVEYOUNG)
6. 그립 (GRIP)
7. 무신사 (MUSINSA)
8. 롯데온 (LOTTEON)
9. 아모레몰 (AMOREMALL)
10. 이니스프리몰 (INNISFREE_MALL)

#### 2. 브랜드 설정 (10개)
- ✅ **설정 파일 위치**: `/Users/amore/ai_cs 시스템/crawler/config/brands.json`
- ✅ **브랜드 수**: **10개**

**브랜드 목록**:
1. 설화수 (SULWHASOO)
2. 라네즈 (LANEIGE)
3. 아이오페 (IOPE)
4. 헤라 (HERA)
5. 에스트라 (ESTEE)
6. 이니스프리 (INNISFREE)
7. 해피바스 (HAPPYBATH)
8. 바이탈뷰티 (VITALBEAUTY)
9. 프리메라 (PRIMERA)
10. 오설록 (OSULLOC)

#### 3. 크롤러 설정
- ✅ **멀티 브랜드 크롤러**: `crawl_multi_brands.py`에 10개 브랜드 하드코딩됨
- ✅ **브랜드 목록 일치**: config/brands.json과 동일

---

## 🔄 스케줄러 동작 확인

### 1. 스케줄러 실행 상태
- ✅ **스케줄러 프로세스**: `dynamic_scheduler.py` 실행 중 (PID: 26774)
- ✅ **수집 주기**: **1시간마다** (매 시간 정각: 00:00, 01:00, 02:00, ...)
- ✅ **수집 대상**: 10개 플랫폼 × 10개 브랜드

### 2. 수집 프로세스
```
초기 실행 → 플랫폼 1 수집 → 플랫폼 2 수집 → ... → 플랫폼 10 수집 → 대기 → 1시간 후 반복
```

### 3. 각 플랫폼별 수집 방식
- **네이버**: `crawl_multi_brands.py` 실행 → 10개 브랜드 검색 → 각 브랜드당 최대 5개 라이브 방송 수집
- **카카오**: `kakao_live_crawler.py` 실행 (타임아웃 발생)
- **기타 플랫폼**: `crawl_multi_brands.py` 또는 플랫폼별 크롤러 실행

### 4. 수집 타임라인 (1시간 주기)
```
00:00 - 스케줄러 트리거
00:01 - 네이버 수집 시작 (10개 브랜드)
00:03 - 카카오 수집 시작
00:05 - 11번가 수집 시작
...
00:30 - 모든 플랫폼 수집 완료
01:00 - 다음 주기 시작
```

---

## ⚠️ 발견된 문제점

### 1. 실제 크롤링 실패
- **문제**: 크롤러가 실제 웹사이트에서 데이터를 수집하지 못함
- **원인**: Selenium 드라이버 문제, 웹사이트 구조 변경, 또는 접근 제한
- **영향**: 수집된 데이터가 0개

**로그 예시**:
```
🎬 네이버 쇼핑라이브 멀티 브랜드 크롤러
대상 브랜드: 라네즈, 설화수, 아이오페, 헤라, 에스트라, 이니스프리, 해피바스, 바이탈뷰티, 프리메라, 오설록
❌ 수집된 데이터가 없습니다.
```

### 2. 카카오 플랫폼 타임아웃
- **문제**: 카카오 크롤러가 10분 타임아웃 발생
- **원인**: 크롤러 실행 시간 초과 또는 무한 대기
- **영향**: 카카오 플랫폼 데이터 수집 실패

### 3. 현재 데이터 소스
- **실제 상황**: 시스템이 **mockData**를 사용 중
- **데이터 위치**: `frontend/src/mockData/realCollectedData.js`
- **데이터베이스**: Supabase에 1000개의 라이브 방송 데이터 저장됨 (12월 1일 기준)

---

## 💡 현재 시스템 동작 방식

### 실제 데이터 흐름
```
[mockData (realCollectedData.js)]
         ↓
[Supabase 데이터베이스] ← import-to-supabase.js로 1회 임포트
         ↓
[백엔드 API (/api/dashboard)]
         ↓
[프론트엔드 Dashboard]
```

### 스케줄러 역할
- **의도**: 1시간마다 실제 웹사이트에서 최신 데이터 크롤링
- **현실**: 크롤러가 데이터를 수집하지 못하고 있음
- **대안**: mockData를 주기적으로 Supabase에 업데이트

---

## 🔧 해결 방안

### 방안 1: MockData 기반 스케줄러 (권장)
현재 시스템이 mockData를 사용하므로, mockData를 주기적으로 Supabase에 업데이트하는 스케줄러 사용

**장점**:
- ✅ 즉시 작동 가능
- ✅ 안정적인 데이터 소스
- ✅ 에러 없음

**구현**:
```javascript
// backend/src/scheduler/mockDataScheduler.js
setInterval(() => {
  // mockData를 Supabase에 업데이트
  const allBrandsData = getAllBrandsData();
  // ... Supabase 업데이트 로직
}, 60 * 60 * 1000); // 1시간
```

### 방안 2: 실제 크롤러 수정
실제 웹사이트에서 데이터를 수집하도록 크롤러 수정

**필요 작업**:
- Selenium 드라이버 설정 확인
- 웹사이트 구조 분석 및 파서 업데이트
- 각 플랫폼별 크롤러 개발/수정
- 타임아웃 및 에러 처리 개선

**단점**:
- ⚠️ 시간 소요 (각 플랫폼별 개발 필요)
- ⚠️ 웹사이트 변경 시 유지보수 필요
- ⚠️ 접근 제한 가능성

### 방안 3: 하이브리드 방식
mockData를 기본으로 사용하되, 일부 플랫폼만 실제 크롤링

**구현**:
- 네이버: 실제 크롤링 (안정적)
- 기타 플랫폼: mockData 사용

---

## 📊 현재 데이터베이스 상태

### Supabase 데이터
- **총 라이브 방송**: 1,000개
- **진행중**: 0개
- **예정**: 318개
- **종료**: 682개
- **플랫폼**: 10개
- **브랜드**: 10개
- **마지막 업데이트**: 2025-12-01

### 데이터 신선도
- ⚠️ **3일 전 데이터** (12월 1일 → 12월 4일)
- ⚠️ 실시간 데이터가 아님
- ⚠️ 스케줄러가 새 데이터를 추가하지 못하고 있음

---

## ✅ 권장 조치사항

### 즉시 조치 (우선순위 높음)

#### 1. MockData 기반 스케줄러 구현
```bash
# Node.js 스케줄러 생성 및 실행
cd "/Users/amore/ai_cs 시스템/backend"
node src/scheduler/mockDataScheduler.js
```

**효과**:
- 1시간마다 mockData를 Supabase에 업데이트
- 안정적인 데이터 갱신
- 에러 없는 운영

#### 2. 스케줄러 자동 시작 설정
```bash
# macOS launchd 사용
cd "/Users/amore/ai_cs 시스템/crawler"
cp com.amore.datacollector.plist ~/Library/LaunchAgents/
launchctl load ~/Library/LaunchAgents/com.amore.datacollector.plist
```

**효과**:
- 시스템 부팅 시 자동 시작
- 크래시 시 자동 재시작

### 중기 조치 (우선순위 중간)

#### 3. 실제 크롤러 개선
- 네이버 크롤러 디버깅 및 수정
- Selenium 드라이버 설정 최적화
- 웹사이트 구조 분석 및 파서 업데이트

#### 4. 모니터링 시스템 구축
- 수집 성공/실패 알림
- 데이터 신선도 체크
- 대시보드에 수집 상태 표시

### 장기 조치 (우선순위 낮음)

#### 5. API 기반 데이터 수집
- 플랫폼 공식 API 사용 (가능한 경우)
- 더 안정적이고 빠른 데이터 수집

---

## 📈 스케줄러 모니터링 명령어

### 상태 확인
```bash
cd "/Users/amore/ai_cs 시스템/crawler"
./check_scheduler_status.sh
```

### 로그 확인
```bash
# 실시간 로그
tail -f logs/dynamic_scheduler_$(date +%Y%m%d).log

# 최근 50줄
tail -50 logs/dynamic_scheduler_$(date +%Y%m%d).log
```

### 프로세스 확인
```bash
ps aux | grep dynamic_scheduler.py
```

### 스케줄러 재시작
```bash
# 기존 프로세스 종료
pkill -f dynamic_scheduler.py

# 새로 시작
cd "/Users/amore/ai_cs 시스템/crawler"
nohup python3 dynamic_scheduler.py > logs/scheduler_service.log 2>&1 &
```

---

## 🎯 결론

### 설정 상태: ✅ 정상
- ✅ 10개 플랫폼 설정 완료
- ✅ 10개 브랜드 설정 완료
- ✅ 스케줄러 실행 중
- ✅ 1시간 주기 설정 완료

### 동작 상태: ⚠️ 부분 정상
- ✅ 스케줄러가 1시간마다 실행됨
- ✅ 10개 플랫폼을 순차적으로 처리 시도
- ⚠️ 실제 크롤링은 실패 (데이터 수집 0개)
- ⚠️ 일부 플랫폼 타임아웃 발생

### 데이터 상태: ⚠️ 주의 필요
- ✅ Supabase에 1,000개 데이터 저장됨
- ⚠️ 데이터가 3일 전 것 (2025-12-01)
- ⚠️ 실시간 업데이트 안 됨

### 권장사항: 🔧 MockData 스케줄러 구현
현재 시스템이 mockData를 사용하므로, Python 크롤러 대신 **Node.js 기반 mockData 스케줄러**를 구현하여 안정적으로 운영하는 것을 권장합니다.

---

## 📝 추가 참고사항

### 현재 스케줄러 로그 위치
- **일별 로그**: `logs/dynamic_scheduler_YYYYMMDD.log`
- **서비스 로그**: `logs/scheduler_service.log`
- **통계 파일**: `output/dynamic_scheduler_stats.json`

### 스케줄러 설정 파일
- **플랫폼**: `config/platforms.json`
- **브랜드**: `config/brands.json`
- **스케줄러 코드**: `dynamic_scheduler.py`

### 관련 문서
- **스케줄러 가이드**: `/Users/amore/ai_cs 시스템/데이터_수집_스케줄러_가이드.md`
- **PRD**: `/Users/amore/ai_cs 시스템/prd`
